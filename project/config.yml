training_config:
  model_name: "google-bert/bert-base-cased"
  num_labels: 3
  output_dir: "project/results"
  batch_size: 128
  epochs: 5
  learning_rate: 0.0001
  seed: 42
  warmup_steps: 500
  weight_decay: 0.01

tokenizer:
  max_length: 128

wandb_config:
  project: "huggingface"
  entity: "NLI_Project"
  api: "f3b43f15e4b9d81f71b4be703dcc32e5d01189f2"
